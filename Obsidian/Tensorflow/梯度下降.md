$$
w_{t+1} = w_t - lr * \frac{\partial loss}{\partial w_t}
$$
$$
b_{t+1} = b - lr * \frac{\partial loss}{\partial b_t}
$$
$$
w_{t+1} * x + b_{t+1} \rightarrow y
$$
```python
import tensorflow as tf

w = tf.Variable(tf.constant(5, dtype=tf.float32))
lr = 0.2 # 0.001\0.999
epoches = 40

for epoche in range(epoches):
    with tf.GradientTape() as tape:
        loss = tf.square(w + 1)
    grads = tape.gradient(loss, w)

    w.assign_sub(lr * grads)
    print(f"After {epoche} epoche, w is {w.numpy()}, loss is {loss}")
```
```
After 35 epoche, w is -0.9999999403953552, loss is 1.4210854715202004e-14
After 36 epoche, w is -0.9999999403953552, loss is 3.552713678800501e-15
After 37 epoche, w is -0.9999999403953552, loss is 3.552713678800501e-15
After 38 epoche, w is -0.9999999403953552, loss is 3.552713678800501e-15
After 39 epoche, w is -0.9999999403953552, loss is 3.552713678800501e-15
```